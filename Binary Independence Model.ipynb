{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c75088b-33dc-4d72-ba52-3d7236430b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8f7f679-a2ae-4b4a-8ea2-84a7b073a047",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocessing function to extract words from text\n",
    "def preprocess(text):\n",
    "    return re.findall(r'\\b\\w+\\b', text.lower())\n",
    "# Function to load \n",
    "def load_documents(folder_path):\n",
    "    docs = {}\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.txt'):\n",
    "            with open(os.path.join(folder_path, filename), 'r',  encoding='utf-8') as file: # as this fle is not in the proper encoding i need to utf encoding\n",
    "                docs[filename] = preprocess(file.read())  # Store preprocessed words\n",
    "    return docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1f57f37-12b8-4e69-bd12-8c56e13fef6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to compute term frequencies and document frequencies\n",
    "def compute_statistics(docs):\n",
    "    doc_count = len(docs)  # Total number of documents\n",
    "    term_doc_freq = defaultdict(int)  # Tracks in how many docs each term appears\n",
    "    term_freq = defaultdict(lambda: defaultdict(int))  # Tracks term frequencies in each document\n",
    "\n",
    "    for doc_id, words in docs.items():\n",
    "        word_set = set(words)  # Unique words in the document for doc frequency\n",
    "        for word in words:\n",
    "            term_freq[doc_id][word] += 1  # Count term frequency\n",
    "        for word in word_set:\n",
    "            term_doc_freq[word] += 1  # Count how many documents contain this word\n",
    "\n",
    "    return term_freq, term_doc_freq, doc_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eeb6bb4a-aad6-452e-a2e5-53db2e45c9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to compute relevance probabilities using Binary Independence Model (BIM)\n",
    "def compute_relevance(query, term_freq, term_doc_freq, doc_count):\n",
    "    scores = {}\n",
    "    for doc_id in term_freq:\n",
    "        score = 1.0  # Start with an initial relevance score of 1\n",
    "        for term in query:\n",
    "            tf = term_freq[doc_id].get(term, 0)  # Term frequency in this doc\n",
    "            df = term_doc_freq.get(term, 0)  # Document frequency of the term\n",
    "            p_term_given_relevant = (tf + 1) / (sum(term_freq[doc_id].values()) + len(term_doc_freq))  # Smoothed probability\n",
    "            p_term_given_not_relevant = (df + 1) / (doc_count - df + len(term_doc_freq))  # Smoothed probability for not relevant\n",
    "            score *= (p_term_given_relevant / p_term_given_not_relevant)  # Multiply probabilities\n",
    "        scores[doc_id] = score  # Store the final score for this document\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f311b27-9911-4db5-9588-102cc44bb8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Main retrieval function\n",
    "def retrieve_documents(folder_path, queries):\n",
    "    docs = load_documents(folder_path)  # Load documents from folder\n",
    "    term_freq, term_doc_freq, doc_count = compute_statistics(docs)  # Compute term and doc frequencies\n",
    "\n",
    "    for query in queries:\n",
    "        query_terms = preprocess(query)  # Preprocess the query (tokenization, case normalization)\n",
    "        scores = compute_relevance(query_terms, term_freq, term_doc_freq, doc_count)  # Get relevance scores\n",
    "        ranked_docs = sorted(scores.items(), key=lambda item: item[1], reverse=True)  # Sort documents by score\n",
    "        \n",
    "        # Print results for this query\n",
    "        print(f\"Query: {query}\")\n",
    "        for doc_id, score in ranked_docs:\n",
    "            print(f\"Document: {doc_id}, Score: {score:.4f}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f3e0d1b-e0ae-47f2-9bb7-8dff247a270b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: beautiful new dress\n",
      "Document: Beauty and the Beast Story.txt, Score: 0.0711\n",
      "Document: Cinderella Story.txt, Score: 0.0597\n",
      "Document: The honest woodcutter.txt, Score: 0.0283\n",
      "Document: A Frog and two Fishes Story.txt, Score: 0.0176\n",
      "Document: Friends Forever Story.txt, Score: 0.0160\n",
      "Document: The King Of Forest Lion and The Mou.txt, Score: 0.0093\n",
      "\n",
      "Query: friends\n",
      "Document: A Frog and two Fishes Story.txt, Score: 0.6862\n",
      "Document: Friends Forever Story.txt, Score: 0.4982\n",
      "Document: The King Of Forest Lion and The Mou.txt, Score: 0.2770\n",
      "Document: Cinderella Story.txt, Score: 0.1363\n",
      "Document: The honest woodcutter.txt, Score: 0.1265\n",
      "Document: Beauty and the Beast Story.txt, Score: 0.0786\n",
      "\n",
      "Query: king who kills fish\n",
      "Document: The King Of Forest Lion and The Mou.txt, Score: 0.1547\n",
      "Document: Friends Forever Story.txt, Score: 0.0600\n",
      "Document: A Frog and two Fishes Story.txt, Score: 0.0455\n",
      "Document: The honest woodcutter.txt, Score: 0.0135\n",
      "Document: Cinderella Story.txt, Score: 0.0034\n",
      "Document: Beauty and the Beast Story.txt, Score: 0.0020\n",
      "\n"
     ]
    }
   ],
   "source": [
    "folder_path = r'D:\\jupter notebook\\books'\n",
    "queries = [\"beautiful new dress\", \"friends\",\"king who kills fish\"]\n",
    "retrieve_documents(folder_path, queries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d8ce2b-0059-49f4-8f21-c5e19b6b53b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be430b5-db4c-4896-b161-1fa64d5b6ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14cc29f-45ea-4672-91b9-e4c2dc63fa28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ed8d92-15d9-4b4a-a77f-43d963baaf11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fdd501-9716-4420-8748-be02c5797931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308e1a5c-1940-4403-b65f-eed0dead2fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15ac69f-ac3d-4c96-9bfc-515bca0b3424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63acac1c-22c0-4d48-89e6-3248beb6ce20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d840b457-86c2-4176-a60f-da01fab0ef4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b71362a-c726-4a5d-b4b5-81b491b557c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9732e36-b2e7-4369-849b-5c1afff21a21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ef6e3b-46a6-4a16-ad28-b2a730c8abd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6018b9-20d2-4607-a9ce-91c27e60c83f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0292db00-1412-4945-be98-4e9661bf1173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20098279-0227-4012-be11-9a63b29281df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fe7be5-e87d-4515-8216-f39a8234a09a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198a89ef-1837-4899-99c7-10ace1962f58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad6c647-074d-473b-90cf-25732564ae32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
